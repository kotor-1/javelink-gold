""""" import cv2 import numpy as np from typing import Optional import logging from app.models.schemas import ViewType, Metrics from app.services.events import Events from app.services.detectors import PoseDetector logger = logging.getLogger(__name__) def create_annotated_video( frames: np.ndarray, keypoints: np.ndarray, events: Events, metrics: Metrics, output_path: str, fps: float, view: ViewType ): """ Args: frames: keypoints: events: metrics: output_path: fps: view: """ h, w = frames[0].shape[:2] # VideoWriter fourcc = cv2.VideoWriter_fourcc(*'mp4v') out = cv2.VideoWriter(output_path, fourcc, fps, (w, h)) # font = cv2.FONT_HERSHEY_SIMPLEX font_scale = 0.7 font_thickness = 2 for i, frame in enumerate(frames): annotated = frame.copy() # if i < len(keypoints): draw_skeleton(annotated, keypoints[i]) # if events.penultimate_frame == i: cv2.putText(annotated, "PENULTIMATE", (50, 50), font, font_scale, (255, 255, 0), font_thickness) # cv2.line(annotated, (w//2, 0), (w//2, h), (255, 255, 0), 2) if events.plant_frame == i: cv2.putText(annotated, "PLANT", (50, 100), font, font_scale, (0, 255, 255), font_thickness) cv2.line(annotated, (w//2, 0), (w//2, h), (0, 255, 255), 2) if events.release_frame == i: cv2.putText(annotated, "RELEASE", (50, 150), font, font_scale, (0, 255, 0), font_thickness) cv2.line(annotated, (w//2, 0), (w//2, h), (0, 255, 0), 2) # if events.release_frame and i > events.release_frame: if view == ViewType.SIDE: # y_offset = 200 if metrics.release_angle_deg is not None: text = f"Angle: {metrics.release_angle_deg:.1f} deg" cv2.putText(annotated, text, (50, y_offset), font, font_scale, (255, 255, 255), font_thickness) y_offset += 30 if metrics.release_speed_mps is not None: text = f"Speed: {metrics.release_speed_mps:.1f} m/s" cv2.putText(annotated, text, (50, y_offset), font, font_scale, (255, 255, 255), font_thickness) y_offset += 30 if metrics.release_height_m is not None: text = f"Height: {metrics.release_height_m:.2f} m" cv2.putText(annotated, text, (50, y_offset), font, font_scale, (255, 255, 255), font_thickness) else: # y_offset = 200 if metrics.plant_foot_progression_deg is not None: text = f"Foot Angle: {metrics.plant_foot_progression_deg:.1f} deg" cv2.putText(annotated, text, (50, y_offset), font, font_scale, (255, 255, 255), font_thickness) y_offset += 30 if metrics.shoulder_hip_separation_deg is not None: text = f"Separation: {metrics.shoulder_hip_separation_deg:.1f} deg" cv2.putText(annotated, text, (50, y_offset), font, font_scale, (255, 255, 255), font_thickness) # cv2.putText(annotated, f"Frame: {i}", (w-150, 30), font, 0.5, (200, 200, 200), 1) out.write(annotated) out.release() logger.info(f"Annotated video saved: {output_path}") def draw_skeleton(image: np.ndarray, keypoints: np.ndarray): """ Args: image: keypoints: (17, 2) """ # COCO connections = [ (PoseDetector.LEFT_SHOULDER, PoseDetector.RIGHT_SHOULDER), (PoseDetector.LEFT_SHOULDER, PoseDetector.LEFT_ELBOW), (PoseDetector.LEFT_ELBOW, PoseDetector.LEFT_WRIST), (PoseDetector.RIGHT_SHOULDER, PoseDetector.RIGHT_ELBOW), (PoseDetector.RIGHT_ELBOW, PoseDetector.RIGHT_WRIST), (PoseDetector.LEFT_SHOULDER, PoseDetector.LEFT_HIP), (PoseDetector.RIGHT_SHOULDER, PoseDetector.RIGHT_HIP), (PoseDetector.LEFT_HIP, PoseDetector.RIGHT_HIP), (PoseDetector.LEFT_HIP, PoseDetector.LEFT_KNEE), (PoseDetector.LEFT_KNEE, PoseDetector.LEFT_ANKLE), (PoseDetector.RIGHT_HIP, PoseDetector.RIGHT_KNEE), (PoseDetector.RIGHT_KNEE, PoseDetector.RIGHT_ANKLE), ] # for connection in connections: pt1 = tuple(keypoints[connection[0]].astype(int)) pt2 = tuple(keypoints[connection[1]].astype(int)) cv2.line(image, pt1, pt2, (0, 255, 0), 2) # for kp in keypoints: cv2.circle(image, tuple(kp.astype(int)), 5, (0, 0, 255), -1) 